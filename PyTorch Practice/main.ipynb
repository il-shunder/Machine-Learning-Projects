{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "tensor([1, 2])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(5)\n",
    "print(x)\n",
    "\n",
    "x = torch.tensor((1,2))\n",
    "print(x)\n",
    "\n",
    "x = torch.empty(2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size():  torch.Size([2, 3])\n",
      "x.shape:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# check size\n",
    "print(\"x.size(): \", x.size())\n",
    "print(\"x.shape: \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# check data type\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# requires_grad argument\n",
    "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
    "# later in your optimization steps\n",
    "# e.g. this is a variable in your model that you want to optimize\n",
    "x = torch.tensor([5.5, 3], requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0.6148, 0.6072, 0.2317],\n",
      "        [0.2530, 0.3209, 0.7107]])\n",
      "tensor([[1.6265, 1.6468, 4.3153],\n",
      "        [3.9524, 3.1164, 1.4070]])\n"
     ]
    }
   ],
   "source": [
    "# Operations\n",
    "x = torch.ones(2, 3)\n",
    "y = torch.rand(2, 3)\n",
    "\n",
    "# addition\n",
    "z = x + y\n",
    "\n",
    "# subtraction\n",
    "z = x - y\n",
    "\n",
    "# multiplication\n",
    "z = x * y\n",
    "\n",
    "# division\n",
    "z = x / y\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2027, 0.4967, 0.9797],\n",
      "        [0.6863, 0.0182, 0.9716],\n",
      "        [0.8638, 0.0555, 0.3902]])\n",
      "x[:, 0] tensor([0.2027, 0.6863, 0.8638])\n",
      "x[0, :] tensor([0.2027, 0.4967, 0.9797])\n",
      "x[0, 0] tensor(0.2027)\n",
      "x[0, 0].item() 0.20274841785430908\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "x = torch.rand(3, 3)\n",
    "print(x)\n",
    "\n",
    "print(\"x[:, 0]\", x[:, 0])\n",
    "print(\"x[0, :]\", x[0, :])\n",
    "print(\"x[0, 0]\", x[0, 0])\n",
    "\n",
    "# Get the actual value if only 1 element in your tensor\n",
    "print(\"x[0, 0].item()\", x[0, 0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7970, 0.9847, 0.8462, 0.4618],\n",
      "        [0.8342, 0.7803, 0.0045, 0.3656],\n",
      "        [0.8094, 0.5220, 0.5565, 0.5720],\n",
      "        [0.7762, 0.7957, 0.0893, 0.9152]])\n",
      "tensor([0.7970, 0.9847, 0.8462, 0.4618, 0.8342, 0.7803, 0.0045, 0.3656, 0.8094,\n",
      "        0.5220, 0.5565, 0.5720, 0.7762, 0.7957, 0.0893, 0.9152])\n",
      "tensor([[0.7970, 0.9847, 0.8462, 0.4618, 0.8342, 0.7803, 0.0045, 0.3656],\n",
      "        [0.8094, 0.5220, 0.5565, 0.5720, 0.7762, 0.7957, 0.0893, 0.9152]])\n"
     ]
    }
   ],
   "source": [
    "# Reshape with torch.view()\n",
    "x = torch.rand(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # if -1 pytorch will automatically determine the necessary size\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "\n",
    "Converting a Torch Tensor to a NumPy array and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3.])\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Careful: If the Tensor is on the CPU (not the GPU),\n",
    "# both objects will share the same memory location, so changing one\n",
    "# will also change the other\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy to torch with .from_numpy(x), or torch.tensor() to copy it\n",
    "import numpy as np\n",
    "\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a) # they share the same memory location\n",
    "c = torch.tensor(a)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "# again be careful when modifying\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Support\n",
    "\n",
    "By default all tensors are created on the CPU. But we can also move them to the GPU (if it's available ), or create them directly on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4267, 0.7320],\n",
      "        [0.4876, 0.8199]])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x = torch.rand(2, 2).to(device) # move tensors to GPU device if available\n",
    "\n",
    "# it is a small optimizations\n",
    "x = torch.rand(2, 2, device=device)  # or directy create them on GPU if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Autograd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
