{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69caa989",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f13702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "class_names = [\"Plane\", \"Car\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ff07f2",
   "metadata": {},
   "source": [
    "# Datasets Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45872588",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ebcd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc2c7e",
   "metadata": {},
   "source": [
    "# Device Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75841873",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf51a4a",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85bd8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1 = nn.Linear(64 * 2 * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):           # x.shape = N, 3, 32, 32\n",
    "        x = F.relu(self.conv1(x))   # x.shape = N, 16, 30, 30\n",
    "        x = self.pool(x)            # x.shape = N, 16, 15, 15\n",
    "        x = F.relu(self.conv2(x))   # x.shape = N, 32, 13, 13\n",
    "        x = self.pool(x)            # x.shape = N, 32, 6, 6\n",
    "        x = F.relu(self.conv3(x))   # x.shape = N, 64, 4, 4\n",
    "        x = self.pool(x)            # x.shape = N, 64, 2, 2\n",
    "        x = torch.flatten(x, 1)     # x.shape = N, 64 * 2 * 2\n",
    "        x = F.relu(self.fc1(x))     # x.shape = N, 128\n",
    "        x = F.relu(self.fc2(x))     # x.shape = N, 64\n",
    "        x = self.fc3(x)             # x.shape = N, 10\n",
    "        return x\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e0a45a",
   "metadata": {},
   "source": [
    "# Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "641b4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf92ac9",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93c7819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [300], Loss: 1.6696\n",
      "Epoch [1], Step [600], Loss: 1.5611\n",
      "Epoch [1], Step [900], Loss: 1.6708\n",
      "Epoch [1], Step [1200], Loss: 1.4674\n",
      "Epoch [1], Step [1500], Loss: 1.4280\n",
      "Epoch [2], Step [300], Loss: 1.2632\n",
      "Epoch [2], Step [600], Loss: 1.2795\n",
      "Epoch [2], Step [900], Loss: 1.4341\n",
      "Epoch [2], Step [1200], Loss: 1.1430\n",
      "Epoch [2], Step [1500], Loss: 1.0752\n",
      "Epoch [3], Step [300], Loss: 1.3436\n",
      "Epoch [3], Step [600], Loss: 0.9872\n",
      "Epoch [3], Step [900], Loss: 1.0184\n",
      "Epoch [3], Step [1200], Loss: 1.0299\n",
      "Epoch [3], Step [1500], Loss: 0.9368\n",
      "Epoch [4], Step [300], Loss: 0.9210\n",
      "Epoch [4], Step [600], Loss: 0.8720\n",
      "Epoch [4], Step [900], Loss: 1.0026\n",
      "Epoch [4], Step [1200], Loss: 0.8217\n",
      "Epoch [4], Step [1500], Loss: 1.0565\n",
      "Epoch [5], Step [300], Loss: 0.9378\n",
      "Epoch [5], Step [600], Loss: 0.8165\n",
      "Epoch [5], Step [900], Loss: 0.8310\n",
      "Epoch [5], Step [1200], Loss: 0.8464\n",
      "Epoch [5], Step [1500], Loss: 1.1023\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch_index, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = loss_fn(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if (batch_index + 1) % 300 == 0:\n",
    "            print (f'Epoch [{epoch + 1}], Step [{batch_index + 1}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9158247",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3f24804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Net: 66.81%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_samples = len(test_loader.dataset)\n",
    "    n_correct = 0\n",
    "\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(targets)\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        n_correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the Net: {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bac49d",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8428c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'net.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb9349e",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a2fed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('net.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390e602",
   "metadata": {},
   "source": [
    "# Model Testing with Real Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2430f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Bird\n",
      "Prediction: Bird\n",
      "Prediction: Dog\n",
      "Prediction: Plane\n"
     ]
    }
   ],
   "source": [
    "new_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "def load_image(path):\n",
    "    image = Image.open(path)\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "images = [\n",
    "    load_image(\"test_images/bird.jpg\"),\n",
    "    load_image(\"test_images/deer.jpg\"),\n",
    "    load_image(\"test_images/dog.jpg\"),\n",
    "    load_image(\"test_images/plane.jpg\")\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "for image in images:\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    print(f\"Prediction: {class_names[predicted.item()]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
